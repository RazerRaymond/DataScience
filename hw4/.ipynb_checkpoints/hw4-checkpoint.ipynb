{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hw 4: More Linear Regression ðŸŽ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "Collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For this homework, work through **Lab 4 (Predicting Housing Prices with Linear Regression)** first. Most of the things we ask you to do in this homework are explained in the lab. In general, you should feel free to import any package that we have previously used in class. Ensure that all plots have the necessary components that a plot should have (e.g. axes labels, a title, a legend).\n",
    "\n",
    "Furthermore, in addition to recording your collaborators on this homework, please also remember to cite/indicate all external sources used when finishing this assignment. This includes peers, TAs, and links to online sources. Note that these citations will be taken into account during the grading and regrading process.\n",
    "\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Do not change the number of cells!** Your submission notebook should have exactly one code cell per problem. \n",
    "* Do **not** remove the `# your code here` line and add you solution after that line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reviewing Regression\n",
    "\n",
    "Let's warm up by considering a few facts about regression. You may refer to your notes, lecture slides, worksheet, and lab to help you answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "\n",
    "**Write-up!** What distinquishes regression tasks from classification and clustering tasks? Consider the input features and outputs of models from each type."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "\n",
    "**Write-up!** Describe the procedure for \"fitting\" a linear regression model. What are the model's parameters and how many of them are there (if we consider each term in $w$ to be a separate parameter)? How do we find the optimal parameters for fitting our training data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3\n",
    "\n",
    "**Write-up!** Given two linear models, how do we decide which one fits the data _better_?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.4\n",
    "\n",
    "**Write-up!** What is training error? What is testing error? What are their interpretations in the context of the data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.5\n",
    "\n",
    "**Write-up!** Consider two models: the first is a linear model; the second is a polynomial model. The second model is more complex. Describe a situation where the polynomial model performs better (has less error) during training but the linear model performs better during testing. What is the name for what happened to the polynomial model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression with More Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's lab, we implemented a linear regression model that could map a single predictor feature to a target variable. In the case of the Boston housing dataset, we could map features like the \"average number of rooms per dwelling\" to a house's price. In reality, however, a single predictor is not enough to get a good model. Additionally, we have data for several predictors so why not make use of that?\n",
    "\n",
    "In this series of problems, let's explore how we can build a multi-dimensional linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn\n",
    "\n",
    "Generalizing our derivation of 1D linear regression to many-dimensionional is non-trivial since we would need to convert our computations into matrix operations, which are beyond the scope of this class. However, that does not mean that we can't\n",
    "do many-dimensional linear regression. The package we will introduce today is [Scikit-learn](https://scikit-learn.org/stable/). It contains many generalized implementations of common learning models and we will be using its implementation of multi-dimensional linear regression here.\n",
    "\n",
    "You have already seen Scikit-learn, or `sklearn`, before since that is where we got our Boston housing data in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn` is very similar to our implementation from the lab, though there is a slight difference: we work with a model object. In the following cell, we create an instance of linear regression model called `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` and `predict` functions that we used previously are analogous to the `fit` and `predict` methods of `model`. Here is a quick example of how to perform 1D linear regression mapping the `CRIM` predictor to housing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CRIM'\n",
    "x_crim = X[:, boston.feature_names.tolist().index(target)].reshape(-1, 1)\n",
    "\n",
    "\n",
    "# you should create a new model object for each new model you create\n",
    "model = LinearRegression()\n",
    "\n",
    "# fitting the model\n",
    "model.fit(x_crim, y)\n",
    "\n",
    "# predicting with the model\n",
    "import numpy as np\n",
    "\n",
    "x_star = np.linspace(x_crim.min(), x_crim.max(), 1001).reshape(-1, 1)\n",
    "model.predict(x_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "**Write-up!** There are several things wrong with the example above. What do you see? `HINT`: think back to the model building part of the data science workflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2\n",
    "\n",
    "Now that we are familiar with `sklearn`, let's start building a linear model that uses all of the features in our dataset. You can refer to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for more information about how to use `LinearRegression`.\n",
    "\n",
    "**Try this!** Build a model that uses _all_ of the predictor features in the Boston housing dataset. Remember to create a new instance of `LinearRegression` and assign it to the `model` variable. Also make sure that you do a train/test split of your data so we can evaluate our model after training (use `random_state=10` so we can compare our results to the ones from `Lab4`; refer to the lab for an example of how to do this). If you were successful, you will see the weights for the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "# Get the model parameters\n",
    "b = model.intercept_\n",
    "w = model.coef_\n",
    "print(b)\n",
    "print(w)\n",
    "\n",
    "# Now, w is a vector! With a weight parameter for every feature.\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3\n",
    "\n",
    "Now that we have a trained model, we can use it to make some predictions using the testing set.\n",
    "\n",
    "**Try this!** Use your model to compute the predicted prices of the points in your testing set and store these into the variable `y_prediction`. Then, compute the RMSE of these predictions and store the value in `rmse`. If all went well you should see the RMSE value you computed as the output of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "assert np.isscalar(rmse), 'RMSE should be a scalar value'\n",
    "\n",
    "f'RMSE: {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4\n",
    "\n",
    "Let's talk about this result.\n",
    "\n",
    "**Write-up!** What did you notice about this result and how does it compare to those of individual predictors from `Lab4`? Is this what you expected to see?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introducing a New Metric\n",
    "\n",
    "RMSE is a good measure for how well a model fits, but one could argue it is not the most intuitive. An alternative measure is $R^2$, or the **coefficient of determination**, which is essentially a measure of how close the data are to the fitted regression line. Whereas RMSE is a number in the units of the original target variable, $R^2$ is a value between 0 and 1, where increasing values indicate better fit. In this way, $R^2$ is a good place to start when evaluating a regression model because it is easy to interpret.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n (y_i - f(x_i))^2}{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n (y_i - \\bar y)^2}$$\n",
    "\n",
    "> _For those who are interested_: Those of you that are statistically savvy, or just simply read the lab, will remember that these sums are mean squared errors. The numerator is the MSE of the true values compared to the predicted value and the denominator is the MSE of the true value relative to the mean value. The denominator is the variance of the response variable (eg. house price). One way to interpret this metric is that it computes the the ratio between how much variation is explained by the model and the total variation in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "**Try this!** Complete the function below so that it computes the $R^2$ value of a model given some `predictions` and their true `labels`. To receive full credit, implement the math yourself; do not rely on other, already implemented functions. Store your computed result in the `r2` variable.\n",
    "\n",
    "> Do **not** use any built-in functions from scikit-learn for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(predictions, labels):\n",
    "    '''computes the r-squared metric of a model given some PREDICTIONS and their true LABELS'''\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    assert np.isscalar(r2), 'R2 should be a scalar value'\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your computation is correct, the following assertion will run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(r_squared(y_prediction, y_test), model.score(X_test, y_test)), 'The value computed was incorrect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using a More Complex Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of options we can choose from when it comes to picking a model to use when analyzing our data. In this section, we will take a look at a more complex model: **polynomial regression**. We will also investigate some of the considerations one should make when picking a model.\n",
    "\n",
    "![poly_reg](utility/pics/poly-regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Toy Data\n",
    "\n",
    "As mentioned in earlier, it is really hard to visualize many-dimensional datasets so for this section we will fall back to the toy data we used from `Lab4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.loadtxt('utility/data/toy_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression models are really just extensions of the linear models that we are already familiar with. The difference comes from how we preprocess our data. The specifics of how this works is beyond the scope of this course (see CSE417 for more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a polynomial model, we will need to do some preparation. `sklearn`'s models require that the input data is a $n$-dimensional array. Since our input array `x` is a 1D array for the toy data set, we will need to do is to reshape it into a 2D array. The function in the following cell, `reshape` will take care of this for you â€” use it when applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = lambda x: x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1\n",
    "\n",
    "The next thing we will need to do is to fit a linear model that will serve as our baseline.\n",
    "\n",
    "**Try this!** Create a new linear model and fit it with the toy data set and create a plot showing the scattered data points `x, y` and the predicted values of fthe model. You don't need to worry about making a train/test split for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utility.util import configure_plots\n",
    "\n",
    "configure_plots() # for pretty plots\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Polynomial Regression\n",
    "\n",
    "Next, let's implement a function that produces fitted polynomial regression models. Again, you don't need to worry too much about how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def make_poly(x, y, degree=2):\n",
    "    '''creates and returns a polynomial regression model fit with input data X and Y'''\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=degree)\n",
    "    poly_model = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                           (\"linear_regression\", LinearRegression())])\n",
    "\n",
    "    return poly_model.fit(reshape(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2\n",
    "\n",
    "Let's try using the `make_poly` function.\n",
    "\n",
    "**Try this!** Use `make_poly` to, well, make a polynomial regression model with a `degree` of 2. This model will fit the data with a quadratic function. Store the model you created in `poly2_model` and create a plot showing the scattered data points `x, y` and the predicted values of the model. Make sure your graph has the proper components. `HINT` you will need to make an array of equally spaced values over an interval (see [`np.linspace`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)) for your predicted values; refer to `Lab4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3\n",
    "\n",
    "Nice that worked well! Let's up the complexity again. Try to play around with the degree and find the one that produces the \"best-fitting\" model.\n",
    "\n",
    "**Try this!** Use `make_poly` and try to find the \"best-fitting\" model by expermenting with the `degree` argument. Store this model in `poly_best_model`. Then, create a plot showing the scattered data points `x, y` and the predicted values of the model. Make sure your graph has the proper components. `HINT` you can use the `r_squared` metric you implemented from before to evaluate the fit of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Models\n",
    "\n",
    "Let's compare the RMSE and $R^2$ metrics for the models that we have produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.4\n",
    "\n",
    "**Try this!** Fill in the following `for` loop to print out the RMSE and $R^2$ metrics for each model in `models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear': linear_model,\n",
    "    '2nd Order Polynomial': poly2_model,\n",
    "    'Best Fitting Polynomial': poly_best_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5\n",
    "\n",
    "**Write-up!** What do you notice about the scores? Given these results, which model would you pick to deliver to a client? Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Up Against the Real Function\n",
    "\n",
    "What if I told you the true function was $$y = 0.16x + 20$$\n",
    "\n",
    "The following function, `ground_truth`, will return `x` and `y` values produced by the true function with some added noise. We can use this to produce other points that could have been generated by the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(n):\n",
    "    '''returns N random samples from the function above'''\n",
    "    \n",
    "    w, b = 0.16, 120\n",
    "    noise = np.random.rand(n) * 300\n",
    "    noise = noise - np.mean(noise)\n",
    "    x = np.random.randint(0, 2000, n)\n",
    "    y = w * x + b + noise\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.6\n",
    "\n",
    "**Try this!** With `ground_truth`, make a plot that shows these four things:\n",
    "1. The points from the toy dataset\n",
    "2. 200 points generated from the true function\n",
    "3. The linear model\n",
    "4. The \"best-fit\" polynomial model\n",
    "5. The true function\n",
    "\n",
    "You don't need to retrain the models for this part. To receive full points, ensure that your plot has all of the proper components, including a legend (see `Lab4` for an example of how to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.7\n",
    "\n",
    "**Write-up!** What happened in the plot from [Problem 3.6](#Problem-3.6)? What does the tell us about model complexity? Why must we be careful of the models that we use to analyze our data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE217",
   "language": "python",
   "name": "cse217"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
